{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e50894a6",
   "metadata": {},
   "source": [
    "# **Testing the gen AI note book** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bc8ccd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to gen AI\n"
     ]
    }
   ],
   "source": [
    "print(\"Welcome to gen AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e9c6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.2\", temperature=0.1, max_tokens=1000)\n",
    "response = llm.invoke(\"What is the sum  of 55 + 65?\")\n",
    "response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262d3f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# ChatGoogleGenerativeAI and API_TOKEN are already defined in previous cells\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "GEMINI_API_TOKEN = os.getenv('GEMINI_TOKEN')\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.1, max_tokens=1000, google_api_key=GEMINI_API_TOKEN)\n",
    "response = llm.invoke(\"What is the sum  of 55 + 65100?\")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61256493",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "GROK_API_TOKEN = os.getenv('GROQ_TOKEN')\n",
    "llm = ChatGroq(model=\"deepseek-r1-distill-llama-70b\", temperature=0.1, api_key=GROK_API_TOKEN)\n",
    "response = llm.invoke(\"What is the sum of 55 + 65100?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6ecf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.2\", temperature=0.1, max_tokens=1000)\n",
    "response = llm.invoke(\"What is the today wethere in hyderabad?\")\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84f76bd",
   "metadata": {},
   "source": [
    "## **TOOL CALLING:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb80b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_numbers(a: int, b: int) -> int:\n",
    "    \"\"\"Adds two numbers.\"\"\"\n",
    "    return a + b\n",
    "def today_weather(city: str) -> str:\n",
    "    return f\"Todays weather in {city} is sunny with a high of 30°C and a low of 20°C.\"\n",
    "\n",
    "#print(today_weather_report)\n",
    "\n",
    "llm_tool=llm.bind_tools([today_weather, add_numbers])\n",
    "# llm.add_tool(\"today_weather\", today_weather, description=\"Get today's weather in a given city.\")\n",
    "response = llm_tool.invoke(\"What is the today weather in hyderabad? and what is the weather in bangalore? and what is the sum of 55 + 65?\")\n",
    "if response.tool_calls[2][\"name\"] == \"add_numbers\":\n",
    "    argument = response.tool_calls[2][\"args\"]\n",
    "    print(f\"Tool call for add_numbers with arguments: {argument}\")\n",
    "\n",
    "    result = add_numbers(int(argument['a']), int(argument['b']))\n",
    "    print(f\"Result of add_numbers: {result}\")\n",
    "\n",
    "if response.tool_calls[0][\"name\"] == \"today_weather\":\n",
    "    argument = response.tool_calls[0][\"args\"]\n",
    "   # print(f\"Tool call for add_numbers with arguments: {argument}\")\n",
    "\n",
    "    result = today_weather((argument['city']))\n",
    "    print(f\"today weather: {result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
